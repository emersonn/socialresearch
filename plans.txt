Dependencies: tweepy, sqlalchemy, mysql-python, colorama, textblob
  python -m textblob.download_corpora

Crawling Instagram
  - Take a look at the popular page for a particular location
    - Record each step through the photos and the person who has the photos
      - Record each comment, likes
  - "You cannot use the Instagram API to crawl or store users' media without their express consent."
    - Maybe ask around and for permission to label someone's Instagram ideals? It gives them
      a personality? Make it into a viral site to ask what their Instagram is and gives them
      stats about themselves?
      - Take a look at their captions, hashtags, comments, likes, emojis used?
        - Counts of emojis, average, standard deviaions?
        - Most liked comments, most commented pictures, most liked pictures, most expressive hashtags?
      - Maybe get other American students to rate the American's personalities and how outgoing they are?
        On a scale of 1 to 10 how revealing is this picture? How much can you tell from this picture?
        How much emotion does this express?
        - Elo scale on how crazy the picture is? Maybe focus on one thing? How much emotions is this? Swipe
          left or swipe right?
          - What kind of emotion does this picture express? Happy, sad, nothing?

Crawling Twitter
  - API.trends_place() of Germany and places around the United States
    - What do people most talk about? What about their opinions on Fergueson or something? What are their
      emotions? What type of hashtags do they use? What do their friends tweet about?
    - API.search()
    - Sentiment analysis with text classification? NLTK Python? What kind of hashtags do people use in addition
      to the sentiment analysis? text-processing.com

  - Crawling
    - Get the trends. Store as a Trend model with a particular date.
      - Store tweets that follow the trend at that exact time, ~1000.
      - Trends will point to all the Tweets that relate to it.
      - Eventually crawl the tweets and the users that are in the tweets?
        - Have a user object and analyze their personality in the database.

  - Workflow
    - Crawler to populate database with trends, tweets
      - Analyze the trends by looking at most popular trends?
    - Analysis of Tweets
      - Sentiment analysis of tweets to populate database of understanding NLTK
      - Analyze positive/negative sentiment, most common words for particular users
        how much information they share, the location, the places they eat, the emojis they use?
    - Participation in Trends? Especially controversial trends?
    - Need another crawler that takes the streaming API of a particular place and just stores those tweets without trends

  - Analysis
    - Happy/sad? Share personal information (pronouns present)?
      - Textblob and nltk
        - Classify maybe different stats with positive, negative and then combine the distributions of each to
          get a general idea of the particular tweet
            - Sentiment, personal information, can you tell who this person is from this tweet, are they talking about/to
              someone (personal conversation)
    - 3 string columns with pos/neg or however many classifiers there need to be and 3 classifier columns
      with the probability distributions. Then have a script that allows classification by column because now
      rows without classifications can then be classified.

  - Website
    - Fun website that uses the data
      - Displays the research and findings
      - Comparison to average twitter user with:
        - Length of tweets
        - Most common words in your tweets
        - Random tweet of yours
        - Classifications
          - Sentiment
            - Most sentimental tweet, positive or negative
            - Average sentiment, graph of distribution showing where they are
    - Main page has just a world map and Live updates of tweets from places
      and has a button that asks if you want to be analyzed and another button
      that pushes the page down to statistics about the research
    - Fix all parts that may need updating
    - Need analytics
    - AngularJS loads API hook full of statistics and data needed to create graphs
      - Timer that polls new data every so often

    - Dependencies
      - Flask
        - Make sure to fix static file servings
        - Fix the returns of the random numbers
        - Should I start caching the user names?
      - Alembic

    - Need to add comments for literally everything!

    - Person makes call to API -> API looks up in Database for most recent update
    - Script kept Alive that continuously crunches numbers and keeps numbers updated
      with new stats and pushes new rows to the database

    - Just cache actually. Update the cache depending on how long the database takes...?

    - Random tweets around the world that pop up on a map
    - Graph of most common words
    - Average sentiment towards a certain filter of words
    - Some type of connection map, words that are commonly found with other words look at NLTK examples
    - Most common words in most common places
    - What types of things do people talk about when they talk about religion?
      - Common words found with religion
      - People who talk about religion what do they talk about?
      - Direct messages to other people what are they talked about?

    - Get tweets that have not been classified with tags, limit to 100, then tag them then keep tagging
    - Get all tweets for a specified location and classify by a certain group of tags
      - Get sentiment and all necessary words
    - Get a random sample of around ~1000 tweets
      - Get sentiment, tags, etc.

    - Migrate to PostgreSQL instead? Store JSON objects?
    - Keep track of words and their frequencies

    - Migrate to PostgreSQL with new database. Fix locations or use firehose. Add screen names and
      other data that may be necessary. Add a SQL migration schema.
    - Optionally use MongoDB and add to a database based on analysis.
    - Optionally keep same database, add sql migration schema, change database to what is needed
      (add screen names, etc)

    - Todo:
      - Install Alembic (done)
      - Init Alembic (done)
      - Remove excess model columns, add necessary columns
        - Screen names (done), analyzed date (done), better location/place/coordinates (done), tags (religion, etc)
      - Add the new columns to the stream script
      - Add new models for words
        - Frequency
      - Migrate database
      - Create script for analysis
      - Fix stream placement for better location/place/coordinates


    - Todo for production:
      - Install flask, Alembic
      - Alembic follow setup to generate files, modify .ini, and env.py
      - Migrate database
      - Fix state file serving, etc.


      - "import sys
        import os.path

        sys.path.append(os.path.join(os.path.dirname(__file__), '..'))"

    - Do not change files (necessary to change in production):
      - settings.py, alembic.ini

- Notes:
  - python -m socialresearch.twitter.crawl_trends
  - python -m socialresearch.twitter.crawl_stream

- Important Circus Settings:
  circusd --daemon socialresearch.ini --log-output social.log --log-level debug --pidfile circus.pid
  circusctl [status]
  pkill circusd
